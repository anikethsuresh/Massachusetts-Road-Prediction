{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.executing_eagerly())\n",
    "tf.config.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "img_width = 512\n",
    "img_height = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'test_labels', 'train', 'train_labels', 'val', 'val_labels']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"archive/tiff/\"\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmp = \"archive/bmp/\"\n",
    "folders = os.listdir(bmp)\n",
    "filenames =  [[],[],[],[],[],[]]\n",
    "i=0\n",
    "for folder in folders:\n",
    "    images = os.listdir(bmp + folder)\n",
    "    for image in images:\n",
    "        filenames[i].append(str(bmp + folder + \"/\" + image))\n",
    "    i += 1\n",
    "test, test_labels, train, train_labels, val, val_labels = filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filenames(filepath1, filepath2):\n",
    "    pil_image1 =  tf.io.read_file(filepath1)\n",
    "    image1 = tf.io.decode_bmp(pil_image1, channels=0)\n",
    "    pil_image2 =  tf.io.read_file(filepath2)\n",
    "    image2 = tf.io.decode_bmp(pil_image2, channels=0)\n",
    "    return (image1,image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader():\n",
    "    def __init__(self, filenames1, filenames2, batch_size):\n",
    "        # filenames: list of files\n",
    "        self.filenames1 = filenames1\n",
    "        self.filenames2 = filenames2\n",
    "        self.dataset = None\n",
    "        print(\"{} filenames received\".format(len(filenames1)))\n",
    "        print(\"{} filenames received\".format(len(filenames2)))\n",
    "        self.batch_size = batch_size\n",
    "        self.run()\n",
    "        \n",
    "    def read_filenames(self, filepath1, filepath2):\n",
    "        pil_image1 =  tf.io.read_file(filepath1)\n",
    "        image1 = tf.io.decode_bmp(pil_image1, channels=0)\n",
    "        image1 = tf.image.resize(image1, [500,500])\n",
    "        image1 = tf.image.pad_to_bounding_box(image1, 6, 6, img_height, img_width)\n",
    "        image1 = tf.cast(image1, tf.float32)\n",
    "        pil_image2 =  tf.io.read_file(filepath2)\n",
    "        image2 = tf.io.decode_bmp(pil_image2, channels=0)\n",
    "        image2 = tf.image.resize(image2, [500,500])\n",
    "        image2 = tf.image.pad_to_bounding_box(image2, 6, 6, img_height, img_width)\n",
    "        image2 = tf.cast(image2, tf.int32)\n",
    "        return [image1,image2]\n",
    "\n",
    "    def run(self):\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.filenames1, self.filenames2))\n",
    "        self.dataset = self.dataset.shuffle(len(self.filenames1), reshuffle_each_iteration=True)\n",
    "        self.dataset = self.dataset.map(self.read_filenames, num_parallel_calls=10)\n",
    "        self.dataset = self.dataset.batch(self.batch_size)\n",
    "#         self.dataset = self.dataset.prefetch(1)\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 filenames received\n",
      "49 filenames received\n",
      "1108 filenames received\n",
      "1108 filenames received\n",
      "14 filenames received\n",
      "14 filenames received\n"
     ]
    }
   ],
   "source": [
    "test_data = DataReader(test, test_labels, batch_size)\n",
    "# print(list(test_data.dataset.take(1).as_numpy_iterator())[0].shape)\n",
    "# test_labels_data = DataReader(test_labels, batch_size)\n",
    "train_data = DataReader(train,train_labels, batch_size)\n",
    "# train_labels_data = DataReader(train_labels, batch_size)\n",
    "val_data = DataReader(val,val_labels, batch_size)\n",
    "# val_labels_data = DataReader(val_labels, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data\n",
    "# fig, axs = plt.subplots(3, 3)\n",
    "# fig.set_figheight(10)\n",
    "# fig.set_figwidth(10)\n",
    "# x = list(test_data.dataset.take(9).as_numpy_iterator())[0][:9]\n",
    "# print(x[0].shape)\n",
    "# index = 0\n",
    "# for i in range(3):\n",
    "#     for j in range(3):\n",
    "#         axs[i][j].imshow(x[0][index,:,:,:])\n",
    "#         index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test Labels data\n",
    "# fig, axs = plt.subplots(3, 3)\n",
    "# fig.set_figheight(10)\n",
    "# fig.set_figwidth(10)\n",
    "# x = list(test_data.dataset.take(9).as_numpy_iterator())[0][:9]\n",
    "# index = 0\n",
    "# for i in range(3):\n",
    "#     for j in range(3):\n",
    "#         axs[i][j].imshow(x[index])\n",
    "#         index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection of the shape of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data = (2, 512, 512, 3)\n",
      "Output data = (2, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input data = {}\".format(list(test_data.dataset.take(1).as_numpy_iterator())[0][0].shape))\n",
    "print(\"Output data = {}\".format(list(test_data.dataset.take(1).as_numpy_iterator())[0][1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check to see that the data is one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  0, 255]), array([243812,  18332], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(test_data.dataset.take(1).as_numpy_iterator())[0][1][1]\n",
    "print(x.shape)\n",
    "np.unique(x, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation (Figure out how to set the final output: 2 classes or 1000x1000 ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(None, 512, 512, 3), dtype=float32)\n",
      "Block 1 : (None, 256, 256, 64)\n",
      "Block 2 : (None, 128, 128, 128)\n",
      "Block 3 : (None, 64, 64, 256)\n",
      "Block 4 : (None, 64, 64, 512)\n",
      "Tensor(\"activation_10/Relu:0\", shape=(None, 128, 128, 256), dtype=float32)\n",
      "Tensor(\"activation_6/Relu:0\", shape=(None, 128, 128, 256), dtype=float32)\n",
      "Block 3 up : (None, 128, 128, 256)\n",
      "Block 2 up : (None, 256, 256, 128)\n",
      "(None, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import callbacks, optimizers\n",
    "from tensorflow.python.keras.models import Model, load_model, model_from_json\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Conv2DTranspose, Concatenate\n",
    "\n",
    "inp = Input((img_width,img_height,3))\n",
    "print(inp)\n",
    "x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(inp)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "block_1_out = Activation('relu')(x)\n",
    "x = MaxPooling2D()(block_1_out)\n",
    "print(\"Block 1 : {}\".format(x.shape))\n",
    "# Block 2\n",
    "x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "block_2_out = Activation('relu')(x)\n",
    "x = MaxPooling2D()(block_2_out)\n",
    "print(\"Block 2 : {}\".format(x.shape))\n",
    "# Block 3\n",
    "x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "block_3_out = Activation('relu')(x)\n",
    "x = MaxPooling2D()(block_3_out)\n",
    "print(\"Block 3 : {}\".format(x.shape))\n",
    "# Block 4\n",
    "x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "block_4_out = Activation('relu')(x)\n",
    "\n",
    "print(\"Block 4 : {}\".format(x.shape))\n",
    "\n",
    "x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', name = 'Conv2DTranspose_UP2')(block_4_out)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "print(x)\n",
    "print(block_3_out)\n",
    "x = Concatenate()([x, block_3_out])\n",
    "x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "print(\"Block 3 up : {}\".format(x.shape))\n",
    "# UP 3\n",
    "x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', name = 'Conv2DTranspose_UP3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Concatenate()([x, block_2_out])\n",
    "x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "print(\"Block 2 up : {}\".format(x.shape))\n",
    "# UP 4\n",
    "x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', name = 'Conv2DTranspose_UP4')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Concatenate()([x, block_1_out])\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def dice_coef(y_true, y_pred):\n",
    "\n",
    "    y_true_f = tf.cast(K.flatten(y_true), tf.float32)\n",
    "    y_pred_f = tf.cast(K.flatten(y_pred), tf.float32)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "#     intersection = tf.cast(intersection, tf.int32)\n",
    "    return (2. * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0) \n",
    " \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=x)\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=dice_coef,\n",
    "              metrics=[dice_coef_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/554 [..............................] - ETA: 8:14 - loss: 1.0639 - dice_coef_loss: -0.0639WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 1.7695s). Check your callbacks.\n",
      "554/554 [==============================] - ETA: 0s - loss: 0.0685 - dice_coef_loss: 0.9315WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_test_batch_end` time: 0.5617s). Check your callbacks.\n",
      "554/554 [==============================] - 1055s 2s/step - loss: 0.0685 - dice_coef_loss: 0.9315 - val_loss: 0.0046 - val_dice_coef_loss: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1986c2eda08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data.dataset,\n",
    "          verbose=1,\n",
    "          epochs=1,\n",
    "          validation_data = val_data.dataset,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,512,512,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-39a5b5156160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compute Stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mout_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mout_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Min = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 386\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36m_merge_function\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(tensors, axis)\u001b[0m\n\u001b[0;32m   2879\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mragged_concat_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2881\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1652\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[0;32m   1653\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,512,512,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "# Compute Stats\n",
    "out_pred = model(tuple(train_data.dataset.take(1))[0][0][:1]).numpy()\n",
    "out_true = tuple(train_data.dataset.take(1))[0][1][:1]\n",
    "print(\"Min = {}\".format(np.min(out_pred)))\n",
    "print(\"Max = {}\".format(np.max(out_pred)))\n",
    "print(\"Shape of output_pred = {}\".format(np.shape(out_pred)))\n",
    "print(\"Shape of output_true= {}\".format(np.shape(out_true)))\n",
    "print(\"Counts of output_pred = {}\".format(np.unique(out_pred, return_counts=True)))\n",
    "print(\"Counts of output_true= {}\".format(np.unique(out_true, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\anike\\anaconda3\\envs\\final_mmd\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_models/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ae7e9e10625d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# tuple(train_data.dataset.take(1))[0][0][1].numpy()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "test_result = model.predict(tuple(train_data.dataset.take(1))[0][0][:1]).reshape((img_height,img_width))\n",
    "axs[0].imshow(tuple(train_data.dataset.take(1))[0][0][1])\n",
    "axs[1].imshow(test_result)\n",
    "# tuple(train_data.dataset.take(1))[0][0][1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(\"saved_models/my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "test_result = loaded(tuple(train_data.dataset.take(1))[0][0][:1]).numpy().reshape((img_height,img_width))\n",
    "print(tuple(train_data.dataset.take(1))[0][0][1].shape)\n",
    "axs[0].imshow(tuple(train_data.dataset.take(1))[0][0][1])\n",
    "# axs[1].imshow(test_result)\n",
    "print(test_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.imwrite('image.png', test_result)\n",
    "test_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = loaded(tuple(train_data.dataset.take(1))[0][0][:1])[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "out[np.where(out<0.5)] = 0\n",
    "out[np.where(out>=0.5)]= 1\n",
    "imgplot = plt.imshow(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(img):\n",
    "    img[np.where(img<0.5)] = 0\n",
    "    img[np.where(img>=0.5)]= 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
